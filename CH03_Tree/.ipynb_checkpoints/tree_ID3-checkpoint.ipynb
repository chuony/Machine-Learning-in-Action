{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树\n",
    "* knn可以完成很多分类任务，但最大的缺点就是无法给出数据的内在含义\n",
    "* 决策树的一个重要任务是为了数据中所蕴涵的知识信息，因此决策树可以使用不熟悉的数据集合，并从中提取出一系列规则。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何划分数据集，何时停止划分数据集：这里采用ID3\n",
    "* ID3算法：按照某个属性划分数据将会产生4个可能的值，则将数据划分为4块，创建4个不同和的分支。(二分法：CART)\n",
    "* 选择哪个合适的特征作为划分的参考属性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例1：简单鱼鉴定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.信息增益\n",
    "* 代码功能：计算给定数据集的熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    for featVec in dataSet: \n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys(): \n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1              # 每个键值都记录当前类别出现的次数\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries   # 计算类别出现的概率\n",
    "        shannonEnt -= prob * log(prob,2)            # 以2为底求对数，并计算香农熵\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单鱼鉴定数据集\n",
    "def createDataSet():\n",
    "    dataSet = [[1, 1, 'yes'],\n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'],\n",
    "               [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    labels = ['no surfacing','flippers']  #特征：不浮出水面是否可以生存；是否有脚蹼\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDat,labels = createDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcShannonEnt(myDat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 熵越高则混合的数据越多。\n",
    "* 通过添加更多的分类，熵变大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'maybe'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat[0][-1] = 'maybe'\n",
    "myDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3709505944546687"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcShannonEnt(myDat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.划分数据集\n",
    "* 获取最大信息增益的方法划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照给定特征划分数据集（axis表示列索引）\n",
    "'''\n",
    "    dataSet:待划分的数据集\n",
    "    axis:划分数据集的特征\n",
    "    value:需要返回的特征的值\n",
    "'''\n",
    "def splitDataSet(dataSet, axis, value):\n",
    "    retDataSet = []                             # 不修改原数据集，创建新的列表对象\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis]     # 除去作为特征划分的那一列，保留其他列\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDat,labels = createDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'yes'], [1, 'yes'], [0, 'no']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitDataSet(myDat,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'no'], [1, 'no']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitDataSet(myDat,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 遍历整个数据集，循环计算香农熵calcShannonEnt()和splitDataSet()函数，找到最好的特征划分方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1      # 最后一列为标签（无需限定list中的数据类型，它们既可以是数字也可以是字符串）\n",
    "    baseEntropy = calcShannonEnt(dataSet)  # 整个数据集的原始熵\n",
    "    bestInfoGain = 0.0; bestFeature = -1\n",
    "    for i in range(numFeatures):           # 遍历所有特征\n",
    "        featList = [example[i] for example in dataSet] # 数据集中的所有第i个特征值都写入list中\n",
    "        uniqueVals = set(featList)         # 从列表中创建集合是python语言得到列表中唯一元素值的最快方法\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:           # 遍历当前特征中的所有唯一属性值\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)   # 所有属性值信息熵加和  \n",
    "        infoGain = baseEntropy - newEntropy                   # 计算信息增益\n",
    "        if (infoGain > bestInfoGain):       \n",
    "            bestInfoGain = infoGain         \n",
    "            bestFeature = i\n",
    "    return bestFeature                     # 返回最好特征划分的索引值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat,labels = createDataSet()\n",
    "chooseBestFeatureToSplit(myDat)   # 结果表明第0个特征是最好的用于划分数据集的特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.递归构建决策树\n",
    "* 已构建子功能模块：得到原始数据集，基于最好的属性值划分数据集，有可能存在多个分支。\n",
    "* 第一次划分后，数据向下传递到树分支的下一个节点...因此采用递归原则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如何定义该叶子节点的类别：多数表决\n",
    "def majorityCnt(classList):\n",
    "    '''\n",
    "        claassList:标签列表 ['yes', 'yes', 'no', 'no', 'no']\n",
    "    '''\n",
    "    classCount={}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys(): classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no surfacing', 'flippers']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 构建递归树：majorityCnt() chooseBestFeatureToSplit() splitDataSet()确定最终划分特征后还要根据此特征划分数据\n",
    "* 终止条件：所有类标签完全相同；使用完所有特征仍不能将数据集划分成唯一类别的分组。接着构建树\n",
    "* 变量myTree：包含了很多代表树结构信息的嵌套字典。本节例子中：该树包含3个叶子节点以及2个判断节点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataSet,labels):\n",
    "    '''\n",
    "    dataSet:数据集\n",
    "    labels:标签列表。\n",
    "    标签列表包含了数据集中所有特征的标签，算法本身不需要这个变量，\n",
    "    但为了给出数据明确的含义，我们将它作为一个输入参数提供。\n",
    "    '''\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    # 第一个终止条件\n",
    "    if classList.count(classList[0]) == len(classList): \n",
    "        return classList[0]  # 类别完全相同时则停止划分。返回的都是类别（yes/no)\n",
    "    # 第二个终止条件\n",
    "    if len(dataSet[0]) == 1: # 遍历完所有特征时返回出现次数最多的.返回的都是类别\n",
    "        return majorityCnt(classList)\n",
    "    # 开始构建树\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet)\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    myTree = {bestFeatLabel:{}}      # 字典变量存储了树的所有信息\n",
    "    del(labels[bestFeat])\n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]       # 复制了类标签，保证每次调用函数的时不改变原始列表的内容\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value),subLabels)\n",
    "    return myTree      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "subLabels = labels[:]\n",
    "在Python中，数字、字符或者元组等不可变对象类型都属于值传递;\n",
    "而字典dict或者列表list等可变对象类型属于引用传递。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat,labels = createDataSet()\n",
    "mytree = createTree(myDat,labels)\n",
    "mytree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.测试算法：使用决策树执行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(inputTree,featLabels,testVec):\n",
    "    firstStr = list(inputTree.keys())[0]   # python2不用List,python3改变了inputTree.keys()的数据类型\n",
    "    secondDict = inputTree[firstStr]\n",
    "    featIndex = featLabels.index(firstStr) # 将标签字符串转换为索引\n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex] == key:\n",
    "            if type(secondDict[key]).__name__=='dict':\n",
    "                classLabel = classify(secondDict[key],featLabels,testVec)\n",
    "            else: classLabel = secondDict[key]\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用isinstance(另外一种)\n",
    "def classify_(inputTree,featLabels,testVec):\n",
    "    firstStr = inputTree.keys()[0]\n",
    "    secondDict = inputTree[firstStr]\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    key = testVec[featIndex]\n",
    "    valueOfFeat = secondDict[key]\n",
    "    if isinstance(valueOfFeat, dict): \n",
    "        classLabel = classify(valueOfFeat, featLabels, testVec)\n",
    "    else: classLabel = valueOfFeat\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no surfacing', 'flippers']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat,labels = createDataSet()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytree = createTree(myDat,labels)\n",
    "mytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata, labels = createDataSet()  #添加这段代码，因为在createTree()函数中删除了最佳划分特征的标签 del(labels[bestFeat])\n",
    "classify(mytree,labels,[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(mytree,labels,[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.使用算法：决策树的存储\n",
    "* 可以预先提炼并存储数据集中包含的知识信息，在需要对事物进行分类时再使用（knn就不行）\n",
    "* python模块pickle序列化对象，可以在磁盘上保存对象，并在需要的时候读取出来。\n",
    "* 任何对象都可以执行序列化操作，字典对象也不例外。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeTree(inputTree,filename):\n",
    "    import pickle\n",
    "    fw = open(filename,'wb')\n",
    "    pickle.dump(inputTree,fw)\n",
    "    fw.close()\n",
    "    \n",
    "def grabTree(filename):\n",
    "    import pickle\n",
    "    fr = open(filename,'rb')\n",
    "    return pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeTree(mytree,'classifierStorage.txt')\n",
    "grabTree('classifierStorage.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例2：使用决策树预测隐形眼镜类型\n",
    "* 隐形眼镜数据集是非常著名的数据集，它包含了很多患者眼部状况的观察条件以及医生推荐的隐形眼镜类型。（书中对数据进行了简单更改）\n",
    "* 隐形眼镜类型：硬材质(hard)、软材质(soft)以及不适合佩戴隐形眼镜(no lenses)。\n",
    "* 特征有四个：age（年龄）、prescript（症状）、astigmatic（是否散光）、tearRate（眼泪数量）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr=open('lenses.txt')\n",
    "lenses=[inst.strip().split('\\t') for inst in fr.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['young', 'myope', 'no', 'reduced', 'no lenses'],\n",
       " ['young', 'myope', 'no', 'normal', 'soft'],\n",
       " ['young', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       " ['young', 'myope', 'yes', 'normal', 'hard'],\n",
       " ['young', 'hyper', 'no', 'reduced', 'no lenses'],\n",
       " ['young', 'hyper', 'no', 'normal', 'soft'],\n",
       " ['young', 'hyper', 'yes', 'reduced', 'no lenses'],\n",
       " ['young', 'hyper', 'yes', 'normal', 'hard'],\n",
       " ['pre', 'myope', 'no', 'reduced', 'no lenses'],\n",
       " ['pre', 'myope', 'no', 'normal', 'soft'],\n",
       " ['pre', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       " ['pre', 'myope', 'yes', 'normal', 'hard'],\n",
       " ['pre', 'hyper', 'no', 'reduced', 'no lenses'],\n",
       " ['pre', 'hyper', 'no', 'normal', 'soft'],\n",
       " ['pre', 'hyper', 'yes', 'reduced', 'no lenses'],\n",
       " ['pre', 'hyper', 'yes', 'normal', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'no', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'no', 'normal', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'yes', 'normal', 'hard'],\n",
       " ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'hyper', 'no', 'normal', 'soft'],\n",
       " ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lensesLabels=['age','prescript','astigmatic','tearRate']\n",
    "lensesTree=createTree(lenses,lensesLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tearRate': {'normal': {'astigmatic': {'yes': {'prescript': {'myope': 'hard',\n",
       "      'hyper': {'age': {'presbyopic': 'no lenses',\n",
       "        'young': 'hard',\n",
       "        'pre': 'no lenses'}}}},\n",
       "    'no': {'age': {'presbyopic': {'prescript': {'myope': 'no lenses',\n",
       "        'hyper': 'soft'}},\n",
       "      'young': 'soft',\n",
       "      'pre': 'soft'}}}},\n",
       "  'reduced': 'no lenses'}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lensesTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
